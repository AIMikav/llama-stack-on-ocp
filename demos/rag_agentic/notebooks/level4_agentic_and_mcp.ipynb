{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
      "cell_type": "markdown",
      "source": "# Level 4: Agentic & MCP (Medium Difficulty)\n\nThis tutorial is aimed at those already familiar with basic Agentic workflows. It is meant to showcase  **sequential tool calls** or **conditional logic** within the context of an agentic workflow.\n\n## Overview\n\nIn this tutorial we will be connecting to a llamastack instance, building an agent with various tools available to it, and inferencing against the agent.\n\n## Prerequisites\n\nBefore starting, ensure you have the following:\n- Access to an openshift cluster.\n- A deployment of the [openshift MCP server](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/mcp-servers/openshift) within the openshift cluster (see the [deployment manifests](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes/mcp-servers/openshift-mcp) for assistance with this).\n- User variables configured (e.g., inference_model, TAVILY_SEARCH_API_KEY, LLAMA_STACK_ENDPOINT).\n- A Tavily API key is required. You can register for one at https://tavily.com/.\n\n## General Setup - Agnostic to all Queries\n\nThese steps will be the same for all 3 queries, with the exception of inputing the Tavily API key - this will only be used for query 2, and so could be ommitted if one only wants to run demos 1 or 3.\n\n### Configuring logging",
      "metadata": {}
    },
    {
      "id": "4481ba68",
      "cell_type": "code",
      "source": "!pip install llama-stack-client==0.1.9 llama-stack==0.1.9",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "25fc0a44",
      "cell_type": "code",
      "source": "from llama_stack_client.lib.agents.event_logger import EventLogger\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nstream_handler = logging.StreamHandler()\nstream_handler.setLevel(logging.INFO)\nformatter = logging.Formatter('%(message)s')\nstream_handler.setFormatter(formatter)\nlogger.addHandler(stream_handler)",
      "metadata": {},
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "681412e1",
      "cell_type": "markdown",
      "source": "### Connecting to llama-stack server\n\nFor the llama-stack instance, you can either run it locally or connect to a remote llama-stack instance.\n\n#### Remote llama-stack\n\n- For remote, be sure to set `remote` to `True` and populate the `remote_llama_stack_endpoint` variable with your llama-stack remote.\n- [Remote Setup Guide](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes)\n\n#### Local llama-stack\n- For local, be sure to set `remote` to `False` and validate the `local_llama_stack_endpoint` variable. It is based off of the default llama-stack port which is `8321` but is configurable with your deployment of llama-stack.\n- [Local Setup Guide](https://github.com/redhat-et/agent-frameworks/tree/main/prototype/frameworks/llamastack)",
      "metadata": {}
    },
    {
      "id": "6fa38ad0",
      "cell_type": "code",
      "source": "remote = True # Use the `remote` variable to switching between a local development environment and a remote kubernetes cluster.\nmodel=\"meta-llama/Llama-3.2-3B-Instruct\"\n\nremote_llama_stack_endpoint = \"your-llama-stack-endpoint\"  # Replace with your llama-stack endpoint if remote is set to True\nlocal_llama_stack_endpoint = \"http://localhost:8321\"\n\ntavily_search_api_key = \"tavily-api-key\" # Replace with your Tavily API key (required for demo 2)\n\nfrom llama_stack_client import LlamaStackClient\n\nif remote:\n    base_url = remote_llama_stack_endpoint\nelse:\n    base_url = local_llama_stack_endpoint\n\nclient = LlamaStackClient(\n    base_url=base_url,\n    provider_data={\n        \"tavily_search_api_key\": tavily_search_api_key # This is required for demo 2\n    })\nlogger.info(f\"Connected to Llama Stack server @ {base_url} \\n\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "66044170",
      "cell_type": "markdown",
      "source": "### Validate tools are available in our llama-stack instance\n\nWhen an instance of llama-stack is redeployed your tools need to re-registered. Also if a tool is already registered with a llama-stack instance, if you try to register one with the same `toolgroup_id`, llama-stack will throw you an error.\n\nFor this reason it is recommended to include some code to validate your tools and toolgroups. This is where the `mcp_url` comes into play. The following code will check that both the `builtin::websearch` and the `mcp::openshift` tools are registered as tools, but if the `mcp::openshift` tool is not listed there, it will attempt to register it using the mcp url.\n\nIf you are running the MCP server from source, the default value for this is: `http://localhost:8000/sse`\nIf you are running the MCP server from a container, the default value for this is: `http://",
      "metadata": {}
    },
    {
      "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
      "cell_type": "code",
      "source": "mcp_url = \"your-mcp-url-here\" # Optional: enter your MCP server url here\n\nregistered_tools = client.tools.list()\nregistered_tools_identifiers = [t.identifier for t in registered_tools]\nregistered_toolgroups = [t.toolgroup_id for t in registered_tools]\nif  \"builtin::websearch\" not in registered_toolgroups: # Required for demo 2\n    error = AssertionError(\"Expected tool `builtin::websearch` to exist, but does not. Please fix your llama-stack deployment.\")\n    logger.error(error)\n    raise error\n    \nif \"mcp::openshift\" not in registered_toolgroups: # required for demos 1 and 3\n    client.toolgroups.register(\n        toolgroup_id=\"mcp::openshift\",\n        provider_id=\"model-context-protocol\",\n        mcp_endpoint={\"uri\":mcp_url},\n    )",
      "metadata": {},
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "9ef5cbe2",
      "cell_type": "markdown",
      "source": "## Query 1: (Agentic) `Check the status of my OpenShift cluster. If itâ€™s running, create a new pod named test-pod in the dev namespace.`",
      "metadata": {}
    },
    {
      "id": "5d285f7d-09a5-47a2-ad92-938e0a8f0d73",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l4_q1\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c9830e45-5633-4eb3-9270-643a27e24f2a",
      "cell_type": "markdown",
      "source": "### Query 2: (Agentic): `Search for the latest Red Hat OpenShift version on the Red Hat website. Summarize the version number and draft a short email to my team.`\n\nPreviously, we instantiated our llama-stack client with our tavily search API key, and connected to our instance of that llama-stack client, before ensuring our required tools and toolgroups are registered to that llamastack instance.\n\nNow we can create our agent, start our agent sessions, ask our LLM the question, and print the responses.",
      "metadata": {}
    },
    {
      "id": "fe55883a-6887-43dd-9498-5333a51799e2",
      "cell_type": "code",
      "source": "from llama_stack_client.lib.agents.agent import Agent\n\nagent = Agent(\n    client=client,\n    model=model,\n    instructions=\"\"\"You are a helpful AI assistant, responsible for helping me find and communicate information back to my team.\n    You have access to a number of tools.\n    Whenever a tool is called, be sure return the Response in a friendly and helpful tone.\n    When you are asked to search the web you must use a tool.\n    When signing off on emails, please be sure to include: - Sent from my llama-stack agent in the signature\n    \"\"\",\n    tools=[\"builtin::websearch\", \"mcp::openshift\"],\n    tool_config={\"tool_choice\":\"auto\"},\n    sampling_params={\n        \"max_tokens\":4096,\n        \"strategy\": {\"type\": \"greedy\"},\n    }\n)\n\n\nsession_id = agent.create_session(session_name=\"Draft_email_with_latest_OCP_version\")\nprompt = \"\"\"Search for the web for the latest Red Hat OpenShift version on the Red Hat website. Summarize the version number and draft an email to convey this information.\"\"\"\nturn_response = agent.create_turn(\n    messages=[\n        {\n            \"role\":\"user\",\n            \"content\": prompt\n        }\n    ],\n    session_id=session_id,\n    stream=True,\n)\nfor log in EventLogger().log(turn_response):\n    log.print()\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\u001b[33minference> \u001b[0m\u001b[97m\u001b[0m\n,\u001b[32mtool_execution> Tool:brave_search Args:{'query': 'latest Red Hat OpenShift version'}\u001b[0m\n,\u001b[32mtool_execution> Tool:brave_search Response:{\"query\": \"latest Red Hat OpenShift version\", \"top_k\": [{\"title\": \"Red Hat Enhances Security and Virtualization Experience with Latest ...\", \"url\": \"https://www.redhat.com/en/about/press-releases/red-hat-enhances-security-and-virtualization-experience-latest-version-red-hat-openshift\", \"content\": \"Red Hat, Inc., the world's leading provider of open source solutions, today announced the general availability of Red Hat OpenShift 4.18, the latest version of the industry\\u2019s leading hybrid cloud application platform powered by Kubernetes. Red Hat OpenShift 4.18 introduces new features and capabilities designed to streamline operations and security across IT environments and deliver greater consistency to all applications, from cloud-native and AI-enabled to virtualized and traditional. Additionally, for users looking for virtualization in the public cloud, Red Hat OpenShift Virtualization is now available on Oracle Cloud Infrastructure as a technology preview. Red Hat OpenShift 4.18 is now available, introducing new features and capabilities designed to streamline operations and security across IT environments and deliver greater consistency to all applications, from cloud-native and AI-enabled to virtualized and traditional.\", \"score\": 0.9296516, \"raw_content\": null}, {\"title\": \"Red Hat OpenShift 4.17: What you need to know\", \"url\": \"https://www.redhat.com/en/blog/what-you-need-to-know-red-hat-openshift-417\", \"content\": \"Based on\\u00a0Kubernetes 1.30 and\\u00a0CRI-O 1.30,\\u00a0 OpenShift 4.17 features expanded control plane options, increased flexibility for virtualization and networking, new capabilities to leverage generative AI, and continued investment in\\u00a0Red Hat OpenShift Platform Plus. Red Hat OpenShift Platform Plus (OPP) is an expanded version of Red Hat OpenShift that provides a comprehensive hybrid cloud platform with built-in security features for enterprises to build, deploy, run, manage, and automate applications at scale. For\\u00a0Red Hat OpenShift Data Foundation (ODF), we\\u2019re promoting to general availability the use of customer-managed ODF with\\u00a0Red Hat OpenShift Service on AWS with hosted control planes clusters in ODF 4.17.z. Ju Lim works on the core Red Hat OpenShift Container Platform for hybrid and multi-cloud environments to enable customers to run Red Hat OpenShift anywhere.\", \"score\": 0.8232293, \"raw_content\": null}, {\"title\": \"What's new in Red Hat OpenShift\", \"url\": \"https://www.redhat.com/en/whats-new-red-hat-openshift\", \"content\": \"What's new in Red Hat OpenShift All Red Hat Red Hat AI portfolioTune small language models and develop and deploy solutions across the hybrid cloud with our line of AI products and services. Red Hat OpenShift AI Artificial intelligenceBuild, deploy, and monitor AI models and apps with Red Hat's open source platforms. Red Hat OpenShift Service on AWS Buy onlineBuy select products and services in the Red Hat Store. Containers, Kubernetes and Red Hat OpenShift Technical Overview (No cost) Why build a Red Hat cloud? Explore Red Hat All Red Hat products Red Hat resources What's new in Red Hat OpenShift Red Hat OpenShift Red Hat Ansible Automation Platform About Red Hat About Red Hat Contact Red Hat\", \"score\": 0.48396602, \"raw_content\": null}, {\"title\": \"Red Hat OpenShift Container Platform Life Cycle Policy\", \"url\": \"https://access.redhat.com/support/policy/updates/openshift/\", \"content\": \"Extended Update Support - Long Life Add-on - Additional Term 1 enables customers to remain with the same minor release of Red Hat OpenShift for a total 24 months, allowing for stable production environments for mission-critical applications. Extended Update Support - Long Life Add-on - Additional Term 1 is provided with all Premium subscriptions for x86-64 versions of Red Hat OpenShift Kubernetes Engine, Red Hat OpenShift Container Platform, and Red Hat OpenShift Platform Plus. The combination of Extended Update Support - Long Life Add-On - Additional Term 1 and Extended Update Support Long Life Add-on - Additional Term 2 (footnote [13]) enables customers to remain with the same minor release of Red Hat OpenShift for a total of 36 months, allowing for stable production environments for mission-critical applications.\", \"score\": 0.46935064, \"raw_content\": null}, {\"title\": \"Download Red Hat Openshift - Red Hat Developer\", \"url\": \"https://developers.redhat.com/products/openshift/download\", \"content\": \"Red Hat OpenShift The trial includes membership in the Red Hat Developer program, which gives you access to evaluation software from Red Hat, tutorials, labs, cheat sheets, e-books, and more. Install Red Hat OpenShift on any supported public cloud providers: Amazon Web services, IBM, and Microsoft Azure. Create a minimal cluster on your desktop or laptop for local development and testing with Red Hat OpenShift Local. Start, stop, and deploy to Red Hat server and runtime products like Wildfly, JBoss EAP (Enterprise Application Platform), Minishift, CDK (Container Development Kit). The CLI that helps developers iterate their code on Red Hat OpenShift and Kubernetes. Red Hat OpenShift Serverless Operator Red Hat OpenShift Service Mesh Operator RED HAT DEVELOPER\", \"score\": 0.39201146, \"raw_content\": null}]}\u001b[0m\n,\u001b[33minference> \u001b[0m\u001b[33mThe\u001b[0m\u001b[33m latest\u001b[0m\u001b[33m version\u001b[0m\u001b[33m of\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m is\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m.\u001b[0m\u001b[33m18\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m version\u001b[0m\u001b[33m introduces\u001b[0m\u001b[33m new\u001b[0m\u001b[33m features\u001b[0m\u001b[33m and\u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m designed\u001b[0m\u001b[33m to\u001b[0m\u001b[33m streamline\u001b[0m\u001b[33m operations\u001b[0m\u001b[33m and\u001b[0m\u001b[33m security\u001b[0m\u001b[33m across\u001b[0m\u001b[33m IT\u001b[0m\u001b[33m environments\u001b[0m\u001b[33m and\u001b[0m\u001b[33m deliver\u001b[0m\u001b[33m greater\u001b[0m\u001b[33m consistency\u001b[0m\u001b[33m to\u001b[0m\u001b[33m all\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m,\u001b[0m\u001b[33m from\u001b[0m\u001b[33m cloud\u001b[0m\u001b[33m-native\u001b[0m\u001b[33m and\u001b[0m\u001b[33m AI\u001b[0m\u001b[33m-enabled\u001b[0m\u001b[33m to\u001b[0m\u001b[33m virtual\u001b[0m\u001b[33mized\u001b[0m\u001b[33m and\u001b[0m\u001b[33m traditional\u001b[0m\u001b[33m.\n,\n,\u001b[0m\u001b[33mHere\u001b[0m\u001b[33m's\u001b[0m\u001b[33m a\u001b[0m\u001b[33m draft\u001b[0m\u001b[33m email\u001b[0m\u001b[33m to\u001b[0m\u001b[33m convey\u001b[0m\u001b[33m this\u001b[0m\u001b[33m information\u001b[0m\u001b[33m:\n,\n,\u001b[0m\u001b[33mSubject\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Latest\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m Version\u001b[0m\u001b[33m Available\u001b[0m\u001b[33m\n,\n,\u001b[0m\u001b[33mDear\u001b[0m\u001b[33m Team\u001b[0m\u001b[33m,\n,\n,\u001b[0m\u001b[33mI\u001b[0m\u001b[33m wanted\u001b[0m\u001b[33m to\u001b[0m\u001b[33m let\u001b[0m\u001b[33m you\u001b[0m\u001b[33m know\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m latest\u001b[0m\u001b[33m version\u001b[0m\u001b[33m of\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m,\u001b[0m\u001b[33m version\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m.\u001b[0m\u001b[33m18\u001b[0m\u001b[33m,\u001b[0m\u001b[33m is\u001b[0m\u001b[33m now\u001b[0m\u001b[33m available\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m version\u001b[0m\u001b[33m includes\u001b[0m\u001b[33m new\u001b[0m\u001b[33m features\u001b[0m\u001b[33m and\u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m that\u001b[0m\u001b[33m aim\u001b[0m\u001b[33m to\u001b[0m\u001b[33m improve\u001b[0m\u001b[33m the\u001b[0m\u001b[33m overall\u001b[0m\u001b[33m experience\u001b[0m\u001b[33m of\u001b[0m\u001b[33m using\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m,\u001b[0m\u001b[33m including\u001b[0m\u001b[33m enhanced\u001b[0m\u001b[33m security\u001b[0m\u001b[33m and\u001b[0m\u001b[33m virtual\u001b[0m\u001b[33mization\u001b[0m\u001b[33m options\u001b[0m\u001b[33m.\n,\n,\u001b[0m\u001b[33mIf\u001b[0m\u001b[33m you\u001b[0m\u001b[33m're\u001b[0m\u001b[33m interested\u001b[0m\u001b[33m in\u001b[0m\u001b[33m learning\u001b[0m\u001b[33m more\u001b[0m\u001b[33m about\u001b[0m\u001b[33m the\u001b[0m\u001b[33m new\u001b[0m\u001b[33m features\u001b[0m\u001b[33m and\u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m in\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m.\u001b[0m\u001b[33m18\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m recommend\u001b[0m\u001b[33m checking\u001b[0m\u001b[33m out\u001b[0m\u001b[33m the\u001b[0m\u001b[33m official\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m website\u001b[0m\u001b[33m for\u001b[0m\u001b[33m more\u001b[0m\u001b[33m information\u001b[0m\u001b[33m.\n,\n,\u001b[0m\u001b[33mBest\u001b[0m\u001b[33m,\n,\u001b[0m\u001b[33m[\u001b[0m\u001b[33mYour\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m]\n,\n,\u001b[0m\u001b[33mSent\u001b[0m\u001b[33m from\u001b[0m\u001b[33m my\u001b[0m\u001b[33m llama\u001b[0m\u001b[33m-stack\u001b[0m\u001b[33m agent\u001b[0m\u001b[97m\u001b[0m\n,\u001b[30m\u001b[0m"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "cf81fb87-19cd-4755-96d5-59628cc75daf",
      "cell_type": "markdown",
      "source": "#### Output Analysis\n\nLets step through the output to further understands whats happening in this Agentic demo.\n\n1. First the LLM sends off a tool call to the `brave_search` to lookup the latest version of Red Hat Openshift.\n2. The LLM recieves the response from the tool call, results of the search, along with the orrigional query. Each search result has:\n    - Title of the webpage\n    - Website URL\n    - Relevant content exerpt from the search result\n    - A score, quanitifying how relevant is the search result to the search query\n    - raw_content from the page\n3. Finally, this context gets passed back to the LLM for the final inference. The inference result starts my responding to my initial with ",
      "metadata": {}
    },
    {
      "id": "aa880bbc-bf69-4777-9417-ef7b13d51785",
      "cell_type": "markdown",
      "source": "### Query 3: (MCP) `Review OpenShift logs for pods pod-123 and pod-456. Categorize each as â€˜Normalâ€™ or â€˜Errorâ€™. If any show â€˜Errorâ€™, send a Slack message to the ops team. Otherwise, show a simple summary.`",
      "metadata": {}
    },
    {
      "id": "bc7957e4-581c-4c3d-aee7-b8e3d9f2d0c0",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l4_q3\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}