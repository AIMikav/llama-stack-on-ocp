{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4f225481-38c7-42b0-98b2-eb90a1023725",
      "cell_type": "markdown",
      "source": "# RAG / Agentic / MCP demos\n\nThis notebook contains a series of demos, showcasing workflows from various agentic use-cases with a deployment of llama-stack. The code for these demos can be found in the [opendatahub-io/llama-stack-on-ocp](https://github.com/opendatahub-io/llama-stack-on-ocp) repo. Thank you to members of the ET org for helping to create these!\n\nThese demos were constructed for the purpose of showing compatability of Llama-stack, as a strategic element within Red Hats AI vision, with elements of Red Hat's existing productized stack. \n\nThe demos are organized in terms of user complexity, starting with lower hanging fruit and moving on to more complicated workflows with chained operations.\n\n## Level 1: Foundational RAG (Low Difficulty)\n\nThe core concept behind all these use cases is **basic retrieval from a defined knowledge base**. It is used to demonstrate that llama-stack has all the necesary primatives for building comprehendsive rag applications witht using an agnetic workflow if it is not required.\n\nThe techstack utilized for this demo:\n    - VectorDB: Milvus Lite (out of the box)\n    - Inferencing: vLLM\n    - LLM: **<NOT SURE WHAT WAS USED @ ILYA>**\n    - UI: Llama Stack Playground\n\n### Query 1: `Summarize the main arguments presented in the research paper \"The Impact of LLMs on Software Development\" (Johnson et al., 2023) that we uploaded.`",
      "metadata": {}
    },
    {
      "id": "b4f70e09-6d40-4f01-bc38-b1741c0b0e88",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l1_q1\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l1_q1\n"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "f71e7618-3462-4750-adf8-db80e8f2ee56",
      "cell_type": "markdown",
      "source": "### Query 2: `What are the standard troubleshooting steps for error code E-404 on the 'GizmoPlus' device?.`",
      "metadata": {}
    },
    {
      "id": "663c089b-6e05-4174-a56c-bd90a994cc20",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l1_q2\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l1_q2\n"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "bcff424c-81b4-478b-8d64-ee49de096bd4",
      "cell_type": "markdown",
      "source": "## Level 2: Simple Agentic (Medium-Low Difficulty)\n\nThe core concept behind all these use cases is **basic single-tool usage**. \n\nThe techstack utilized for this demo:\n    - Inferencing: vLLM\n    - LLM: **<NOT SURE WHAT WAS USED>**\n    - Tools: builtin tools (webseach_\n    - UI: Llama Stack Playground\n\n### Query 1: `Search for recent news articles about advancements in quantum computing.`",
      "metadata": {}
    },
    {
      "id": "d1e08833-b0e1-403a-9123-d8564148471e",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l2_q1\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l2_q1\n"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "27226a0e-e237-4754-ad0b-462aac11111c",
      "cell_type": "markdown",
      "source": "### Query 2: `Find coffee shops near my current location that are open now and have Wi-Fi.`",
      "metadata": {}
    },
    {
      "id": "6f91661b-435b-4a4a-a0d1-3472d75c9f94",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l2_q2\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l2_q2\n"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "80a4afd2-c3ad-4145-b5df-e338c7bfa1da",
      "cell_type": "markdown",
      "source": "### Query 3: `What’s latest in OpenShift?`",
      "metadata": {}
    },
    {
      "id": "121129a1-61b4-47eb-b695-9cc050618611",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l2_q3\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l2_q3\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "fac3e383-af17-48e8-aef5-7d882ffccb05",
      "cell_type": "markdown",
      "source": "## Level 3: Agentic RAG (Medium)\n\nThe core concept of the following use cases is that **retrieval directly informs or enables subsequent agent actions**. \n\nThe techstack utilized for this demo:\n    - Inferencing: vLLM\n    - LLM: **<NOT SURE WHAT WAS USED @ ILYA>**\n    - Tools: builtin tools (webseach), and Rag_tool\n    - UI: Llama Stack Playground\n\n### Query 1: `Summarize the main arguments presented in the research paper \"The Impact of LLMs on Software Development\" (Johnson et al., 2023) that we uploaded.`",
      "metadata": {}
    },
    {
      "id": "ac95e13e-da70-4766-9668-9d9fc9ecfda1",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l3_q1\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l3_q1\n"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "f6acccc3-826f-4442-8572-d4d520fd266b",
      "cell_type": "markdown",
      "source": "### Query 2: `Based on our customer support knowledge base, what are the standard troubleshooting steps for error code E-404 on the GizmoPlus device?`",
      "metadata": {}
    },
    {
      "id": "b9bfde58-5737-46aa-80ff-824541bea84a",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l3_q2\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l3_q2\n"
        }
      ],
      "execution_count": 9
    },
    {
      "id": "a291b874-01d2-4e4d-8739-eec37643b626",
      "cell_type": "markdown",
      "source": "### Query 3: `What does our company's HR policy document state about remote work eligibility for employees based in California?`",
      "metadata": {}
    },
    {
      "id": "f225a938-e69e-4cac-a99d-d6056a690607",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l3_q3\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l3_q3\n"
        }
      ],
      "execution_count": 10
    },
    {
      "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
      "cell_type": "markdown",
      "source": "## Level 4: Agentic & MCP (Medium Difficulty)\n\nThe core concepts behind all these use cases are **sequential tool calls** or **conditional logic** within the context of an agentic workflow.\n\n### Query 1: (Agentic) `Check the status of my OpenShift cluster. If it’s running, create a new pod named test-pod in the dev namespace.`",
      "metadata": {}
    },
    {
      "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
      "cell_type": "code",
      "source": "some_python_code_for_l4_q1()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'some_python_code_for_l4_q1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msome_python_code_for_l4_q1\u001b[49m()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'some_python_code_for_l4_q1' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 11
    },
    {
      "id": "5d285f7d-09a5-47a2-ad92-938e0a8f0d73",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l4_q1\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l4_q1\n"
        }
      ],
      "execution_count": 12
    },
    {
      "id": "c9830e45-5633-4eb3-9270-643a27e24f2a",
      "cell_type": "markdown",
      "source": "### Query 2: (Agentic): `Search for the latest Red Hat OpenShift version on the Red Hat website. Summarize the version number and draft a short email to my team.`",
      "metadata": {}
    },
    {
      "id": "fe55883a-6887-43dd-9498-5333a51799e2",
      "cell_type": "code",
      "source": "# Code bellow written following examples here: https://llama-stack.readthedocs.io/en/latest/building_applications\nfrom llama_stack_client.lib.agents.agent import Agent\nfrom llama_stack_client.lib.agents.event_logger import EventLogger\nfrom llama_stack_client import LlamaStackClient\nimport argparse\nimport logging\nimport json\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nstream_handler = logging.StreamHandler()\nstream_handler.setLevel(logging.INFO)\nformatter = logging.Formatter('%(message)s')\nstream_handler.setFormatter(formatter)\nlogger.addHandler(stream_handler)\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-r\", \"--remote\", help=\"Uses the remote_url\", action=\"store_true\")\nparser.add_argument(\"-s\", \"--session-info-on-exit\", help=\"Prints agent session info on exit\", action=\"store_true\")\nparser.add_argument(\"-a\", \"--auto\", help=\"Automatically runs examples, and does not start a chat session\", action=\"store_true\")\nargs = parser.parse_args()\n\n# model=\"meta-llama/Llama-3.2-3B-Instruct\"\nmodel=\"ibm-granite/granite-3.2-8b-instruct\"\n\n# Connect to a llama stack server\nif args.remote:\n    base_url = os.getenv(\"REMOTE_BASE_URL\")\n    mcp_url = os.getenv(\"REMOTE_MCP_URL\")\nelse:\n    base_url=\"http://localhost:8321\"\n    mcp_url=\"http://host.containers.internal:8000/sse\"\n\nclient = LlamaStackClient(\n    base_url=base_url,\n    provider_data={\n        \"tavily_search_api_key\": os.getenv(\"TAVILY_API_KEY\")\n    })\nlogger.info(f\"Connected to Llama Stack server @ {base_url} \\n\")\n\nagent = Agent(\n    client=client,\n    model=model,\n    instructions = \"\"\"You are a helpful assistant. You have access to a number of tools.\n    Whenever a tool is called, be sure return the Response in a friendly and helpful tone.\n    When you are asked to search the web you must use a tool.\n    \"\"\" ,\n    tools=[\"builtin::websearch\"],\n    tool_config={\"tool_choice\":\"auto\"},\n    sampling_params={\"max_tokens\":4096}\n)\n\n\nsession_id = agent.create_session(session_name=\"Draft_email_with_latest_OCP_version\")\nprompt = \"\"\"Search for the web for the latest Red Hat OpenShift version on the Red Hat website. Summarize the version number and draft an email to convey this information.\"\"\"\nturn_response = agent.create_turn(\n    messages=[\n        {\n            \"role\":\"user\",\n            \"content\": prompt\n        }\n    ],\n    session_id=session_id,\n    stream=True,\n)\nfor log in EventLogger().log(turn_response):\n    log.print()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'llama_stack_client'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Code bellow written following examples here: https://llama-stack.readthedocs.io/en/latest/building_applications\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_stack_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_stack_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventLogger\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_stack_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaStackClient\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_stack_client'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 13
    },
    {
      "id": "aa880bbc-bf69-4777-9417-ef7b13d51785",
      "cell_type": "markdown",
      "source": "### Query 3: (MCP) `Review OpenShift logs for pods pod-123 and pod-456. Categorize each as ‘Normal’ or ‘Error’. If any show ‘Error’, send a Slack message to the ops team. Otherwise, show a simple summary.`",
      "metadata": {}
    },
    {
      "id": "bc7957e4-581c-4c3d-aee7-b8e3d9f2d0c0",
      "cell_type": "code",
      "source": "print(\"some_python_code_for_l4_q3\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "some_python_code_for_l4_q3\n"
        }
      ],
      "execution_count": 14
    },
    {
      "id": "d0f56741-889c-4055-8c2a-e1fbcef9d720",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}