name: Llama stack builds
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
env:
    LLAMA_RELEASE: "0.1.9"


jobs:
  llama-stack-build:
    runs-on: ubuntu-latest
    environment: ci
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
           ref: release-${{env.LLAMA_RELEASE}}
           repository: meta-llama/llama-stack.git

      - name: python deps
        run: |
           sudo apt-get update
           sudo apt-get install -y python3-pip

      - name: login to quay.io
        uses: docker/login-action@v3
        with:
          registry: quay.io
          username: ${{ secrets.QUAY_USERNAME }}
          password: ${{ secrets.QUAY_PASSWORD }}

      - name: Install repo packages
        run: |
          pip install -U .

      - name: modify the build.yaml
        run: |
          sed -i 's/    - inline::faiss/    - inline::milvus/g' llama_stack/templates/remote-vllm/build.yaml

      - name: display contents of buld.yaml
        run: |
          cat llama_stack/templates/remote-vllm/build.yaml

      - name: run llama stack build
        run: |
          USE_COPY_NOT_MOUNT=true LLAMA_STACK_DIR=. llama stack build --template remote-vllm --image-type container

      - name: tag the image
        run: |
          docker tag docker.io/library/distribution-remote-vllm:dev quay.io/redhat-et/llama:vllm-${{env.LLAMA_RELEASE}}

      - name: push the image
        run: |
          docker push quay.io/redhat-et/llama:vllm-${{env.LLAMA_RELEASE}}
